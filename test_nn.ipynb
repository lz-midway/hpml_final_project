{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ed3217-671a-43f1-bdd5-75b965d9e95d",
   "metadata": {},
   "source": [
    "## code for testing functionality of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b94a23b-2e12-4594-8cb9-8a461cd233d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785bf855-753c-42cc-9368-4de168e53560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Layers, loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e748f567-7c95-4813-81ec-78f0b91a6b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 101])\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Layers.BCVNN(image_channels=3, filter_dimension=3).to(device)\n",
    "\n",
    "# Dummy RGB input: batch of 8 images, 3×256×256\n",
    "dummy = torch.randn(8, 3, 256, 256).to(device)\n",
    "out = model(dummy)\n",
    "\n",
    "print(\"Output shape:\", out.shape)\n",
    "# Expected: [8, 101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf2b2f-085c-4572-bf87-ceb085076565",
   "metadata": {},
   "source": [
    "## validation with synthetic, random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4f6b75-ae4e-4fe1-b9aa-e68e2370ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation with synthetic dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import Layers, loaders\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041d347d-06ca-408d-91f0-c1e6f69d1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make synthetic dataset\n",
    "num_samples = 1000\n",
    "num_classes = 101\n",
    "image_size = 256\n",
    "batch_size = 64\n",
    "\n",
    "# Fake RGB images (float32 in [0, 1])\n",
    "X = torch.randn(num_samples, 3, image_size, image_size)\n",
    "# Random integer labels between 0 and num_classes-1\n",
    "y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# Wrap as TensorDataset for easy DataLoader batching\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf41130-3204-4334-a59e-ad9096dfb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, optimizer \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Layers.BCVNN(image_channels=3, filter_dimension=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec621e37-1efb-4d71-8120-46d3dc6bd3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 5it [01:08, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 5, Loss: 4.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 10it [02:59, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 4.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 15it [04:26, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 15, Loss: 4.6140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 16it [04:38, 17.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete. Avg Loss: 4.6152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 5it [01:28, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 5, Loss: 4.6143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 10it [02:54, 17.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 10, Loss: 4.6139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 15it [04:38, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 15, Loss: 4.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training batches: 16it [04:49, 18.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete. Avg Loss: 4.6136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(2):  # a couple of epochs for sanity check\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (images, labels) in tqdm(enumerate(loader), desc=\"training batches\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Verify output shape\n",
    "        assert outputs.shape == (images.size(0), num_classes), \\\n",
    "            f\"Unexpected output shape {outputs.shape}\"\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1} complete. Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9a2888-7622-45ed-bc76-b8d86da10ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation batch:\n",
      "Output shape: torch.Size([64, 101])\n",
      "Predictions: tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15])\n",
      "True labels: tensor([ 87,  45,  42, 100,  84,   6,  42,  25,  31,  44])\n"
     ]
    }
   ],
   "source": [
    "# Evaluation sanity check\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels = next(iter(loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    preds = outputs.argmax(dim=1)\n",
    "\n",
    "    print(\"\\nValidation batch:\")\n",
    "    print(\"Output shape:\", outputs.shape)\n",
    "    print(\"Predictions:\", preds[:10])\n",
    "    print(\"True labels:\", labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfc446-f488-47f7-b684-4a2ae73ab795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159f711-b32c-47c5-b358-170f1626cb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpml pytorch env",
   "language": "python",
   "name": "hpml_pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
